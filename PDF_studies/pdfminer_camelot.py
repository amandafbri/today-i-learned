# You need to install ghostscript as well
import os
import camelot

from pdfminer.high_level import extract_text

# You can also run it in the terminal command: pdf2txt.py PDF_studies/test_data/PDF_with_tables.pdf
text_extracted_from_pdf = extract_text('PDF_studies/test_data/PDF_with_tables.pdf')
print(text_extracted_from_pdf)

"""
'RESUMO\n\nEste documento tem por ﬁnalidade apresentar uma abordagem para a estruturação\nautomática de laudos médicos em português por meio da extração de informações clí-\nnicas utilizando processamento de linguagem natural (NLP) e aprendizado de máquina.\nForam propostas duas arquiteturas, Bi-LSTM-CRF e CRF baseada em features, além\nda técnica de bootstrapping, utilizada para criação de conjunto de dados anotados\na partir de um conjunto pequeno. As métricas precision, recall e F1-score, obtidas\na partir do conjunto de teste, foram todas acima de 80%. As análises de robustez\nmostraram que a solução é promissora e poderá ser aprimorada. A explicabilidade\ndos modelos de CRF, que apresenta características que o algoritmo observou durante\no treinamento, também auxiliou no entendimento do que foi realizado. As implemen-\ntações são escaláveis e adaptáveis, não somente para novas modalidades médicas,\nmas também para outras tarefas dentro da empresa, o que não acontece com o mi-\ncrosserviço de estruturação atual, baseado em expressões regulares. Além disso, os\nresultados mostraram uma potencial otimização de tempo de desenvolvimento e custo\nem produção, simpliﬁcando a estrutura em nuvem vigente.\n\nPalavras-chave: Aprendizado de máquina. Laudos médicos. Extração de informações\nclínicas. Processamento de linguagem natural.\n\n\x0cCapítulo 3. Fundamentação teórica e revisão da literatura\n\n31\n\nfossem treinados vários modelos durante um processo em paralelo. Para determinadas\narquiteturas, existe ainda o variational dropout (GIORGI; BADER, 2019). A diferença é\nque a técnica se aplica a partes especíﬁcas da rede durante múltiplos passos.\n\nCom relação à arquitetura CRF, têm-se outros algoritmos de otimização, apre-\nsentados no quadro 1. Nesse caso, podem utilizar a regularização L1 e/ou L2 ou algum\nmétodo mais especíﬁco. Para o Passive Aggressive, por exemplo, existe um outro tipo\nde coeﬁciente que realiza esse papel.\n\nQuadro 1 – Resumo dos principais algoritmos para a CRF.\n\nAlgoritmo\n\nSigla\n\nLimited-memory\nBroyden-Fletcher-\nGoldfarb-Shanno\n\nL-BFGS\n\nCaracterísticas\nMaximiza o logaritmo da probabilidade dos dados de treino com\nregularização L1 e/ou L2. Melhora os pesos muito lentamente no\ninício, mas converge rapidamente no ﬁnal.\n\nL2-SGD\n\nMaximiza o logaritmo da probabilidade dos dados de treino com\nregularização L2. Aproxima dos pesos ótimos rapidamente, mas\nmostra convergência lenta no ﬁnal.\n\nStochastic Gradient\nDescent with L2 re-\ngularization\n\nAveraged Percep-\ntron\nPassive Aggressive\nAdaptive Regulari-\nzation Of Weight\nVector\n\nAP\n\nCalcula a média dos pesos em todas as atualizações do processo.\nÉ o algoritmo mais veloz no treinamento.\n\nPA\nAROW Também utiliza o loss, porém o computa com uma formulação dife-\n\nUtiliza o loss para atualizar o modelo.\n\nrente.\n\nFonte – Elaborado pela autora com base em (OKAZAKI, 2007).\n\nNo presente projeto os diferentes otimizadores tiveram seu desempenho avali-\nado através de experimentos. Alguns dos parâmetros disponíveis foram variados para\nque seus efeitos no aprendizado do modelo fossem melhor compreendidos.\n\n3.2 MÉTRICAS DE DESEMPENHO\n\nAo treinar um modelo de inteligência artiﬁcial é de suma importância avaliar o\nseu desempenho através de métricas. As mais clássicas, como acurácia, precision,\nrecall e F1-score, são calculadas através da matriz de confusão (indicada na equação\n6), que dispõe sobre o número de classiﬁcações de um modelo para cada categoria ou\nentidade e na qual TP são verdadeiros positivos, FP são falsos positivos, FN os falsos\nnegativos e TN, verdadeiros negativos.\n\n(cid:34)\n\n(cid:35)\n\n.\n\nTP FP\nFN TN\n\n(6)\n\nPara trabalhos que envolvem NLP, deve-se levar em conta ainda a forma de interpre-\ntação sobre o que é um acerto e um erro. Para reconhecimento de entidades, por\nexemplo, pode-se considerar uma predição correta como a extração da entidade exata,\n\n\x0cCapítulo 3. Fundamentação teórica e revisão da literatura\n\n33\n\nPara melhor esclarecer a diferença entre os cálculos do Quadro 2, apresenta-se\num exemplo. Supondo-se que é desejado identiﬁcar duas entidades clínicas em um\nconjunto de laudos médicos, representadas pelos códigos SNOMED-CT "A", "B", "C",\né retornada a seguinte matriz de confusão:\n\nTabela 1 – Matriz de confusão para exemplo ﬁctício de reconhecimento de entidades.\n\nResposta Verdadeira\nA B\n6\n2\n2\n\nC\n3\n0\n6\n\nA 4\nB 1\nC 1\n\nPredição\n\nFonte – Elaborado pela autora com base em (SHMUELI, 2019).\n\nPara as métricas micro, como observam-se todas as entidades ao mesmo tempo,\ncada predição errada é um falso positivo ou negativo, dependendo do ponto de vista.\nPor exemplo, se uma amostra para a entidade "A"é classiﬁcada como "B", então tal\namostra pode ser vista como um falso positivo para "B"e falso negativo para "A". Já\nno caso da macro, o cálculo é feito para cada entidade da mesma maneira que em\num caso binário, seguindo a matriz de confusão e posteriormente se obtém a média.\nDessa forma, para o problema ﬁctício, os resultados são apresentados na Tabela 2.\n\nTabela 2 – Métricas para exemplo ﬁctício de reconhecimento de entidades.\n\nMicro\n\nMacro\n\nRecall\n\n4+2+6\n\n12+6+3+1+0+1+2 = 48% 0.667+0.20+0.667\n\n3\n\n= 51.1%\n\nPrecision\n\n4+2+6\n\n12+6+3+1+0+1+2 = 48% 0.308+0.667+0.667\n\n3\n\n= 54.7%\n\nF1-score\n\n2 ∗ 0.48∗0.48\n\n0.48+0.48 = 48%\n\n0.421+0.308+0.667\n3\n\n= 46.5%\n\nFonte – Elaborado pela autora com base em (SHMUELI, 2019).\n\nPara o presente projeto, ambas as formas, micro e macro, serão contabilizadas.\nComo cada uma delas observa o modelo de IA sob um ponto de vista, é relevante\ncompará-las, principalmente a métrica F1-score.\n\n\x0c'
"""

tables = camelot.read_pdf('PDF_studies/test_data/PDF_with_tables.pdf', pages='1-3')
print(tables)
# <TableList n=3>
print(tables[1].parsing_report)
# {'accuracy': 95.17, 'order': 1, 'page': 3, 'whitespace': 60.0}
print(tables[2].df)
tables.export('PDF_studies/test_data/extracted_tables.csv', f='csv')